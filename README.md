# Salary-Prediction

# Introduction
This project employed three machine learning algorithms (i.e. **Naïve Bayes, K-Nearest Neighbors, and Random Forest**) to predict job salary based on role and requirements. The training set includes 8,000 job descriptions labelled with salary and 5,902 unlabeled descriptions. The development set for validation purpose has 1,737 job descriptions with target labels, and the test set has 1,738 unlabeled job descriptions. This project used the TFIDF and Embedding of job descriptions to make prediction. The objective is to select suitable models following data pre-processing, hyperparameter tuning, and performance metrics interpretation and comparison. This project also attempted to utilize unlabeled data to train models and explored whether it improved performance.

# Method
This project applied four types of input features to make predictions. Firstly, TFIDF and Embedding are the two types of input features. Alternatively, the project incorporated the two traits into one predictive feature. In addition, the project also standardized TFIDF and Embedding values and combined them to generate the fourth type of input feature.
In this project, DummyClassifier is used as the baseline model which predicts the labels of instances randomly and uniformly. Since the target of this project is to predict the correct job salary category, accuracy is used as the primary evaluation metric. The algorithms selected in this project are **Multinomial Naïve Bayes, K-Nearest Neighbors, and Random Forest**. For hyperparameter tuning, the project conducted a **5-fold cross validation** on the training set by using the **GridSearchCV** function in scikit-learn library. After obtaining the optimal parameters, the models would be evaluated on the validation set. The models with the highest validation accuracy within each algorithm would then be used to examine the effect of utilizing unlabeled data. The project implemented Semi-Supervised Learning via the **SelfTrainingClassifier** function in scikit-learn library. The process started by adding 1,000 unlabeled data to the pool, then increase by 500 with each subsequent iteration. The project also explored various **threshold** (prediction probability) and **k_best** (k highest confidence) values to determine which yields the best results. The flow chart of this project is presented below.
![flow chart](https://github.com/W-Hsieh/Salary-Prediction/assets/142127312/31c6d781-5405-4b44-bdfb-f18eb4d0af60)

# Results and Discussion
The accuracy and F1-scores of the baseline models using four types of input features are approximately 0.1 since the models generate predictions uniformly at random from the 10 labels. The results for other models are discussed as follows:
  - **Multinomial Naïve Bayes**
    - Multinomial Naïve Bayes is computationally efficient since it is a data mining approach and easy to train. The algorithm has the shortest training times, averaging approximately 0.019 seconds. In this project, the alpha values to be tuned are in a range of 0 to 20. The training accuracy score clearly decreases as alpha increases. The reason why larger alpha values could result in worse performance is that it changes the proportion of the denominator drastically and add bias in prediction. For this algorithm, the optimal alpha is 0.5, and the accuracy on the validation set is 0.231, which is the worse than best models in the other two algorithms. Despite the fact that Laplace smoothing solves the problem of zero-frequency, this algorithm performs poorly due to its main assumption of feature independence. From the job descriptions and tfidf_words.csv, it's clear that some words are more closely related, like "executive" to "manager" or "director" than to "Singapore." Adding more data can improve the model's accuracy by refining the conditional probability calculations. Nevertheless, the assumption of feature independence is a significant limitation of this algorithm.
  - **K-Nearest Neighbors**
    - The hyperparameter to be tuned in K-Nearest Neighbors is n_neighbors, with a range of 5 to 100. The optimal model performance occurs when n_neighbors equals to 51 with scaled TFIDF and Embedding as the input features.As n_neighbors increases, the accuracy scores for training and validation data progressively converge, and the best n_neighbors for both training and validation data is a value in the middle. Smaller n_neighbors values are more likely to capture noise and produce a model that is not well-generalized, while larger n_neighbors values are prone to aggregate unrelated classes. Hence, these factors would contribute to poorer classifier performance. In addition, the potential reason why the combined scaled input features performs better is that not only does it contains the greatest amount of information, but also because the values are scaled to prevent the dominance of features with larger scale. As a result, the model can calculate the distance between instances more accurately and make correct predictions.
  - **Random Forest**
    - The n_estimators and max_depth attributes are the two attributes used to tune the complexity of Random Forest model. In this project, the best model performance is achieved when n_estimators and max_depth are set to 400 and 40, respectively, with scaled TFIDF and Embedding as the input features. Combining TFIDF and Embedding as input features may improve performance because the model can utilize more features to partition the data and generate more accurate predictions. As n_estimators increases, accuracy generally improves, which demonstrates the effectiveness of ensemble learning. Nonetheless, once a certain threshold is reached (around n_estimators = 300), the performance could level off or even slightly decline. One possible explanation is that the correlation between trees increases when excessive number of decision trees are introduced, leading to lower performance. Figure 5 illustrates that as max_depth increases, the accuracy tends to increase since would be perfectly trained on the training data, and overfitting is more likely to occur, especially for models with larger n_estimators.

Random Forest outperforms other algorithms since the ensemble algorithm is more complex and robust. It has the highest accuracy and F1-scores on validation set. Nevertheless, the training time is significantly longer than the others as shown below.
![result](https://github.com/W-Hsieh/Salary-Prediction/assets/142127312/ea6b8565-a9ef-470e-ac91-d39b5240a104)

**Semi-supervised Learning**
Different threshold and k_best values in the SelfTrainingClassifier were tested, with validation accuracy serving as the evaluation metric for determining the impact of adding unlabeled data.
For Multinomial Naïve Bayes and K-Nearest Neighbors, the accuracy remains unchanged when threshold is greater than 0.7. It is possible that the models fail to identify any points that satisfy the condition and therefore do not add new training data, or that the added points have no beneficial effect. For instance, high threshold value for K-Nearest Neighbors indicates that the unlabeled data is adjacent to an existing labelled data. These data could be viewed as duplicates of the existing data, and the model would not learn new information by adding them. With higher threshold, the added data point would be more likely to be labeled correctly, but smaller amount of data with high similarity to existing points would be added. Hence, the model could potentially learn less in the process. While a greater quantity of unlabeled data could be added with a lower threshold, the pseudo-labels may be incorrect. When a sufficient number of pseudo-labels are false, classifier performance would deteriorate, which could explain the situation depicted in Figure 6 with threshold = 0.5.
k_best = 10 has the best performance in the three models, while k_best = 200 has the worst performance. This is because the method simply selects the k best instances and adds them to the training set, regardless of the confidence level. Thus, probability of inserting incorrect pseudo-labels increases as k increases. Due to the propagation of classification errors, the self-training algorithm may reinforce poor classification decisions. A mechanism that return points to the pool when the classification confidence decreases below a certain level can be implemented to resolve the issue and prevent further propagation error.
![semi](https://github.com/W-Hsieh/Salary-Prediction/assets/142127312/e51708bf-044c-4f61-8b59-ed28ace0d27a)


# Conclusion
In conclusion, all models perform better than the baseline model and Random Forest has the best performance among the three algorithms. It is observed that models with scaled TFIDF and Embedding as the input features have better performance. Additionally, the classification reports reveal that the models have higher F1-scores for 0 and 9 salary bin. <br />
Depending on the amount of unlabeled data added and the values of threshold and k_best, the classifier performance can fluctuate. However, it is observed that small threshold and large k_best could lead to worse model performance since classification errors are propagated. To address this issue, an approach that returns data points to the pool if the confidence level declines below a particular threshold could be applied.

